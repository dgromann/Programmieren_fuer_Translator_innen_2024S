{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN/44k6mKF1EU4qIo+lXNvm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/Programmieren_fuer_Translator_innen_2024S/blob/main/notebooks/LV9_F%C3%BCnfte_Praktische_U%CC%88bung.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2024S: EinfÃ¼hrung ins Programmieren fÃ¼r Translator:innen, Ãœbung (UE), 340273-1**"
      ],
      "metadata": {
        "id": "6zdA0ilhmmAU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **5. Praktische Ãœbung: Das innere eines Language Models**\n",
        "\n",
        "Dieses Notebook stellt die fÃ¼nfte praktische Ãœbung vor, die dazu dient die interne Darstellung von Sprache in einem Language Model kennenzulernen.\n",
        "\n",
        "Dazu mÃ¼ssen erst wieder die erforderlichen Programmbibliotheken installiert werden."
      ],
      "metadata": {
        "id": "uL84K4wIpWbM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "9EDyAJ-krqxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann laden wir das erste Modelle, welches ein mehrsprachiges vortrainiertes Sprachmodell names XLM-RoBERTa (XLM-R) in der kleinen Variante `base` ist."
      ],
      "metadata": {
        "id": "3tF70BBoXxOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google-t5/t5-small\")"
      ],
      "metadata": {
        "id": "jaDlcj7zX9jm"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nun kÃ¶nnen Sie das intern dargestellte Vokabular des Modells mithilfe der Funktion `tokenizer.get_vocab()` ausgeben lassen. Bedenken Sie, dass der Tokenizer sowohl Tokens als auch IDs speichert. Wir sind hier nur an Tokens interessiert.\n"
      ],
      "metadata": {
        "id": "7MiGPz5UYLjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In dieser Form der Tokenisierung werden alle Tokens, die den Beginn eines Wortes darstellen mit einem Unterstrich versehen. Tokens ohne Unterstrich stellen somit die WeiterfÃ¼hrung eines Wortes dar.\n",
        "\n",
        "Um das besser darzustellen, fÃ¼hren Sie bitte eine Tokenisierung auf dem folgenden Beipsielsatz durch, indem Sie einfach"
      ],
      "metadata": {
        "id": "gz8qBgaooDLN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_sentence = \"Diese Ãœbung erlaubt es mir die innere Darstellung des Vokabulars eines Sprachmodells zu analysieren.\"\n",
        "sentence_tokenized = tokenizer.tokenize(example_sentence)\n",
        "print(sentence_tokenized)"
      ],
      "metadata": {
        "id": "xDW62tvzoLbG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Beantworten Sie mithilfe der Funktion `tokenizer.get_vocab()` die folgenden Fragen in der nachstehenden Code-Zelle direkt als Python-Code und -Ausgabe:\n",
        "\n",
        "\n",
        "\n",
        "*   Welcher Datentyp wird von der Funktion `tokenizer.get_vocab()` zurÃ¼ckgegeben? Geben Sie den Datentyp aus.\n",
        "*   Wie viele Tokens sind insgesamt im Modell gespeichert?\n",
        "*   Wenn die Tokens als Liste dargestellt werden, welcher Token ist an Position 300 zu finden?\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "OJ6a_5xBY2a3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.get_vocab()\n",
        "# FÃ¼gen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "collapsed": true,
        "id": "RGBMPJgHYdGS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Erstellen Sie nun eine Funktion, welche alle Tokens, die nur aus einem Zeichen bestehen, zurÃ¼ckgibt.\n",
        "\n",
        "Geben Sie jeweils 30 Tokens aus nur einem Zeichen pro Zeile aus. Das kÃ¶nnen Sie erreichen, indem Sie eine Liste erstellen, die dann alle 30 Tokens bestehend aus nur einem Zeichen ausgegeben wird, auf eine leere Liste zurÃ¼ckgesetzt wird und wieder von neuem mit jeweils 30 Tokens versehen wird.  "
      ],
      "metadata": {
        "id": "0szZZW3nnrX9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FÃ¼gen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "bhlY5_NeqPWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘‹ âš’ **Aufgabe** ðŸ‘‹ âš’ <br>\n",
        "Mithilfe von WordNet werden wir nun eine SchÃ¤tzung der englischen WÃ¶rter in der Liste der Tokens berechnen.\n",
        "\n",
        "Dazu mÃ¼ssen erst wieder die erforderlichen Programmbibliotheken installiert werden und WordNet geladen werden."
      ],
      "metadata": {
        "id": "hpawN7s-q92C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install nltk"
      ],
      "metadata": {
        "id": "rWAqJHZDq9BR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import wordnet\n",
        "\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "tJQyqMy0sZsY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Schreiben Sie dazu eine Funktion, welche Ã¼berprÃ¼ft ob fÃ¼r ein Token ein Synset in WordNet gefunden wird oder nicht (`wordnet.synsets(token)`). ZÃ¤hlen Sie dabei wie viele Tokens ein Synset aufweisen und berechnen Sie die Prozent dieser Anzahl im Vergleich zur Gesamtanzahl der Tokens.\n",
        "\n",
        "Bitte beachten Sie, dass der vorangehende Unterstrich _ bei den Tokens entfernt werden sollte, nicht jedoch jedes Token einen Unterstrich hat.  Acthen Sie bitte auch darauf, dass der Unterstrich eine ganz eigene Encodierung hat und direkt aus der Ausgabe des Vokabulars kopiert werden sollte (nicht als Unterstrich auf der Tastatur eingegeben werden sollte).\n",
        "\n",
        "Wie unterscheidet sich die Prozentzahl der gefundenen Tokens mit oder ohne Entfernung des Unterstrichs?"
      ],
      "metadata": {
        "id": "04WiHF_7tOt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# FÃ¼gen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "cvjw3RQpsv3Y"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}