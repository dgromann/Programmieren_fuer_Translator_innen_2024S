{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSHxqDSn8z+8H2zyUADubV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/Programmieren_fuer_Translator_innen_2024S/blob/main/notebooks/LV6_Sentence_Similarity_mit_L%C3%B6sungen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2024S: Einführung ins Programmieren für Translator:innen, Übung (UE), 340273-1\n",
        "\n",
        "\n",
        "### **Speichern Sie dieses Notebook**\n",
        "\n",
        "Dieses Notebook können Sie jederzeit und in jedem Browser erneut von GitHub (bzw. dem direkten Link in Moodle) öffnen. Um jedoch Ihre eigenen Lösungen und Ihren Code zu speichern, wählen Sie bitte **Datei** bzw. **File** und eine der Speicheroptionen. Die einfachste Speicheroption ist in Google Drive, da dadurch Änderungen im Notebook automatisch im Hintergrund gespeichert werden.\n",
        "\n",
        "Für die Abgabe der praktischen Übungen müssen Sie jedoch das Jupyter-Notebook als .ipynb Datei herunterladen. Dazu klicken Sie auf **Datei** oder **File** und **Herunterladen** oder **Download** und wählen das Format .ipynb aus."
      ],
      "metadata": {
        "id": "9gTU_wXn5DyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation des Notebooks**\n",
        "\n",
        "Fragen und praktische Aufgaben werden hier als ❓**Frage**❓ bzw. 👋 ⚒ **Aufgabe** 👋 ⚒ gekennzeichnet. ❓**Fragen**❓ fordern Sie dazu auf Überlegungen anzustellen bevor Sie etwas praktisch testen. 👋 ⚒ **Aufgaben** 👋 ⚒ erfordern das aktive Schreiben von Code in der grauen Code-Zelle nach der Beschreibung der Aufgabe."
      ],
      "metadata": {
        "id": "_Ha_gYIk5FGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Lektion 11: Sentence Similarity mit und ohne spaCy**\n",
        "Unter Sentence Similarity wird eine Metrik verstanden, welche die semantische Nähe von Sätzen misst, im Gegensatz zu Metriken welche die Ähnlichkeit von Wörtern in Kontexten evaluiert.\n",
        "\n",
        "Eine Anwendung oder ein Modell der Sentence Similarity erhält einen Satz als Eingabe und misst wie ähnlich dieser Satz zu einem oder mehreren anderen Sätzen ist. Dazu wird eine bestimmte Metrik verwendet, z. B. Levenshtein-Distanz oder Kosinus-Ähnlichkeit."
      ],
      "metadata": {
        "id": "ksxAGEVC5LbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Levenshtein-Distanz**\n",
        "\n",
        "Die Levenshtein oder Edit-Distanz misst die Anzahl der folgenden Operationen um die eine Zeichenkette in die andere umzuwandeln: Einfügen, Löschen, Ersetzen.\n",
        "\n",
        "Beispiel Tor-Tier:\n",
        "\n",
        "\n",
        "1.   Ausgangswert: Tor (Anzahl Operationen: 0)\n",
        "2.   Erstezen: \"o\" durch \"i\" zu Tir (Anzahl Operationen: 1)\n",
        "3.   Einfügen: \"e\" zu Tier (Anzahl Operationen: 2)\n",
        "\n",
        "Diese Messung kann auf Wörter aber auch auf längere Zeichenketten wie Sätze angewandt werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "GVCWYf38-ReV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cosine-Similarity**\n",
        "Die Kosinus-Ähnlichkeit oder üblicher Cosine-Similarity bestimmt den Winkel zwischen zwei Vektoren. Dadurch ist es erforderlich erst die Wörter bzw. Sätze in Vektoren umzuwandeln, um dann den Winkel zwischen den Vektoren messen zu können.\n",
        "\n",
        "![Cosine similarity](https://huggingface.co/datasets/huggingface-ml-4-games-course/course-images/resolve/main/en/unit1/unity/cosine.png)\n",
        "\n",
        "Dazu muss allerdings Text erst in Vektoren verwandelt werden. Danach kann anhand der folgenden Formel der Kosinus-Wert berechnet werden.\n",
        "\n",
        "![Kosinus](https://wikimedia.org/api/rest_v1/media/math/render/svg/5b18ea67495071781ab0d1379373872662fa6735)\n",
        "\n",
        "Die Kosinus-Ähnlichkeit liegt zwischen −1 (genau entgegengerichtet) und 1 (genau gleichgerichtet). Bei Ähnlichkeitsanalysen von Text liegt dieser Wert in der Regel im Bereich zwischen 0 und 1. Je näher der Wert zu 1 ist desto ähnlicher sind die Zeichenketten.\n"
      ],
      "metadata": {
        "id": "MjgJpXAhAyaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Anwendungsbeispiele**\n",
        "Diese Berechnung der Ähnlichkeiten zwischen Zeichenketten kann für viele verschiedene Anwendungen sehr hilfreich sein:\n",
        "\n",
        "\n",
        "*   Suchmaschinen\n",
        "*   Maschinelle Übersetzung\n",
        "*   Informationsextraktion\n",
        "*   viele mehr\n",
        "\n"
      ],
      "metadata": {
        "id": "tBmisAm7LEFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als erstes benötigen wir Beispielsätze. Wir verwenden zur Anschauung zwei Sätze auf Deutsch und zwei Sätze auf Englisch."
      ],
      "metadata": {
        "id": "Vf5-79jOFOz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHsKFiuS4RAF"
      },
      "outputs": [],
      "source": [
        "sentence1_de = \"Ein Hund springt auf einem Trampolin.\"\n",
        "sentence2_de = \"Ein Hund hüpft auf einem Trampolin im Garten.\"\n",
        "\n",
        "sentence1_en = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sentence2_en = \"The quick black dog jumps over the brown fox\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im ersten Ansatz verwenden wir einen ganz simplen Ansatz, der einfach die Häufigkeiten von Wörtern des Gesamtvokabulars im Satz zählt. Nehmen wir unsere beiden deutschen Beispielsätze:\n",
        "\n",
        "\n",
        "`Satz 1: Ein Hund springt auf einem Trampolin.`<br>\n",
        "`Satz 2: Ein Hund hüpft auf einem Trampolin im Garten.`\n",
        "\n",
        "\n",
        "Für diesen Korpus besteht unser Gesamtvokabular aus allen Wörtern dieser beiden Sätze ohne Wiederholungen:\n",
        "\n",
        "`{'einem', 'hund', 'garten', 'auf', 'im', 'hüpft', 'springt', 'ein', 'trampolin'}`"
      ],
      "metadata": {
        "id": "SYcq4Xm2F69N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 ⚒ **Aufgaben** 👋 ⚒ <br>\n",
        "Schreiben Sie eine Funktion, welche einen Satz übergeben wird und die alle Wörter im Satz:\n",
        "\n",
        "\n",
        "1.   Kleinschreibung aller Buchstaben im Satz mit sentence.lower()\n",
        "2.   Tokenisierung aller Wörter in einem Satz und entfernen der Punkte (spaCy oder sentence.strip(\".\") + split())\n",
        "\n",
        "Die Funktion soll eine Liste mit allen kleingeschriebenen Tokens eines Satzes zurückgeben. Falls Sie spaCy verwenden wollen, muss erst wieder alles geladen werden."
      ],
      "metadata": {
        "id": "ARihR-HDI3lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "qdAN6qyKOB6U",
        "outputId": "e906211b-9002-4da3-b923-31fc0b39a082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "ro2MODavOD1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante 1: ohne spaCy\n",
        "def preprocess(sentence):\n",
        "  # Fügen Sie hier Ihren Code hier ein\n",
        "  sentence_lower = sentence.lower()\n",
        "  sentence_lower_strip = sentence_lower.strip(\".\")\n",
        "  tokens = sentence_lower_strip.split()\n",
        "  return tokens\n",
        "\n",
        "sent1_tokens = preprocess(sentence1_de)\n",
        "print(sent1_tokens)"
      ],
      "metadata": {
        "id": "L0N5JsaMKvWR",
        "outputId": "cf7d94d3-0669-43b1-9445-baa4cc0799a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ein', 'hund', 'springt', 'auf', 'einem', 'trampolin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante 2: mit spaCy\n",
        "def preprocess_spacy(sentence):\n",
        "  tokens = []\n",
        "  doc = nlp(sentence.lower())\n",
        "  for token in doc:\n",
        "    if token.pos_ != \"PUNCT\":\n",
        "      tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "preprocess_spacy(sentence1_de)"
      ],
      "metadata": {
        "id": "O0vJkSUlT65k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die von Ihnen geschriebene Funktion verwenden wir nun um die Kosinus-Ähnlichkeit zu berechnen. In der nachstehenden Code-Zelle sehen Sie die Umsetzung der Kosinus-Formel in Python zur Berechnung der Textähnlichkeit.\n",
        "\n",
        "👋 ⚒ **Aufgaben** 👋 ⚒ <br>\n",
        "Verwenden Sie den nachstehenden Code um die Ähnlichkeit der beiden englischen Beispielsätze zu berechnen. Beachten Sie, dass bei spaCy dann das geladene Modell geändert werden muss, wenn für die `preprocess`-Funktion spaCy verwendet wird."
      ],
      "metadata": {
        "id": "PbxAeoPuK0L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def vectorize(text, vocab):\n",
        "    # Erstellen einer Vektordarstellung auf Basis von Worthäufigkeiten\n",
        "    vector = [text.count(word) for word in vocab]\n",
        "    return vector\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    # Kosinus-Ähnlichkeit zwischen den beiden Vektoren berechnen\n",
        "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
        "    magnitude_vec1 = math.sqrt(sum(x ** 2 for x in vec1))\n",
        "    magnitude_vec2 = math.sqrt(sum(y ** 2 for y in vec2))\n",
        "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
        "\n",
        "sentence1_tokens = preprocess(sentence1_de)\n",
        "sentence2_tokens = preprocess(sentence2_de)\n",
        "\n",
        "# Gesamtvokabular erstellen\n",
        "vocabulary = set(sentence1_tokens + sentence2_tokens)\n",
        "\n",
        "# Vektoren für die beiden Sätze berechnen\n",
        "sentence1_vector = vectorize(sentence1_tokens, vocabulary)\n",
        "sentence2_vector = vectorize(sentence2_tokens, vocabulary)\n",
        "print(\"Vokabular:\", vocabulary)\n",
        "print(\"Vektor Satz 1:\", sentence1_vector)\n",
        "print(\"Vektor Satz 2:\", sentence2_vector)\n",
        "\n",
        "# Kosinus-Ähnlichkeit zwischen diesen beiden Vektoren berechnen\n",
        "cos_similarity = cosine_similarity(sentence1_vector, sentence2_vector)\n",
        "\n",
        "print(\"Satz 1:\", sentence1_de)\n",
        "print(\"Satz 2:\", sentence2_de)\n",
        "print(\"Ähnlichkeit:\", cos_similarity)"
      ],
      "metadata": {
        "id": "6YD0kcbKGdyz",
        "outputId": "09872b77-b3fc-490f-8137-6c57ecd0f851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'auf', 'springt', 'trampolin', 'hüpft', 'ein', 'im', 'hund', 'garten', 'einem'}\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
            "[1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "Satz 1: Ein Hund springt auf einem Trampolin.\n",
            "Satz 2: Ein Hund hüpft auf einem Trampolin im Garten.\n",
            "Ähnlichkeit: 0.7216878364870323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In spaCy gibt die Möglichkeit Wörter und Sätze direkt in Vektoren darzustellen, da die spaCy-Modelle bereits Vektordarstellungen bereitstellen. Diese Vektoren zählen aber nicht die im Satz enthaltenen Wörter, sondern verwenden neuronale Netze um Wörter in Vektoren darzustellen.\n",
        "\n",
        "Falls Sie die Code-Zellen oben nicht ausgeführt haben, dann führen Sie bitte die folgenden Code-Zellen aus um die spaCy-Modelle und Programmbibliothek zu laden. Die verschiedenen vortrainierten Modelle in spaCy finden sie [hier](https://spacy.io/models/en).\n",
        "\n"
      ],
      "metadata": {
        "id": "KchEAcYuNKRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "L589-bFgORK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "TI145lWMOa5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann kann spaCy direkt verwendet werden um Vektoren zu erstellen."
      ],
      "metadata": {
        "id": "H8_e3wVDOf0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(\"Tor\").vector"
      ],
      "metadata": {
        "id": "d1ZvQbT9OfOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dasselbe funktionert auch für Sätze."
      ],
      "metadata": {
        "id": "WxlNBScwOo3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(sentence1_de).vector"
      ],
      "metadata": {
        "id": "GrVEiuniOqfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um nun Sätze zu vergleichen, können in spaCy enthaltene Funktionen verwendet werden."
      ],
      "metadata": {
        "id": "3QQteiSoPCP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(sentence1_de)\n",
        "doc2 = nlp(sentence2_de)\n",
        "\n",
        "similarity = doc1.similarity(doc2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "id": "xWCDlyKbPGsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oder wir verwenden die Vektordarstellungen in unserer `cosine_similarity`-Funktion. Das Ergebnis ist dasselbe."
      ],
      "metadata": {
        "id": "h968FxRtPXxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity =cosine_similarity(nlp(sentence1_de).vector, nlp(sentence2_de).vector)\n",
        "print(similarity)"
      ],
      "metadata": {
        "id": "-W8ZJRm4PXFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 ⚒ **Aufgaben** 👋 ⚒ <br>\n",
        "Berechnen Sie die Kosinus-Ähnlichkeit auf den beiden englischen Beispielsätzen mithilfe von spaCy. Achtung: Dazu muss das richtige Modelle in spaCy geladen werden."
      ],
      "metadata": {
        "id": "Lw44GsdbPpuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fügen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "eKhUPqk4QjU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lektion 12: Sentence Similarity mit Hugging Face 🤗**\n",
        "\n",
        "[Hugging Face](https://huggingface.co/) 🤗 ist eine Platform für maschinelles Lernen, Computerlinguistik und Data Science. NLP-Expert*innen und -Begeisterte teilen auf Hugging Face vortrainierte Modelle, Datensätze, Code und Informationen.\n",
        "\n",
        "Die Platform selbst bietet einheitliche Methoden um Modelle und Datensätze in Python zu laden und zu verwenden. Um Hugging Face in Google Colab nutzen zu können müssen wir zwei Bibliotheken von Hugging Face installieren."
      ],
      "metadata": {
        "id": "QxZ0uvu7Q1HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "7YjHCJkhXNBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der große Unterschied zu den vorherigen Methoden ist, dass wir mithilfe von Hugging Face die Vektordarstellung von großen vortrainierten Modellen abrufen können."
      ],
      "metadata": {
        "id": "l8-IqDFwXOwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/stsb-xlm-r-multilingual')\n",
        "\n",
        "# Vektordarstellung der beiden Sätze abrufen\n",
        "embedding_1= model.encode(sentence1_de)\n",
        "embedding_2 = model.encode(sentence2_de)\n",
        "\n",
        "cos_sim = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
        "print(\"Die Kosinus-Ähnlichkeit ist:\", cos_sim.item())"
      ],
      "metadata": {
        "id": "E6MTPvKvWyeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mithilfe von Hugging Face können wir auch bereits existierende Datensätze laden und verwenden, z. B.[Glue](https://huggingface.co/datasets/nyu-mll/glue) mit vielen verschiedenen Tasks einschließlich Semantic Textual Similarity."
      ],
      "metadata": {
        "id": "PH4_VO0lbMhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"nyu-mll/glue\", \"stsb\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "inrZ7K09bb2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann können die einzelnen drei Teile des Datensatzes `train`, `validation`, `test` direkt angesprochen werden und wie ein Key eines Dictionarys behandelt werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "sFzN4raPdDF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][10])"
      ],
      "metadata": {
        "id": "nXzIL3EIdDef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Und über diesen Datentypen kann auch iteriert werden. Die Funktion `select(range(10))`dient hier der Auswahl von 10 Beispielen.  "
      ],
      "metadata": {
        "id": "hDj8BHtXha6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for line in dataset['train'].select(range(10)):\n",
        "  print(line)"
      ],
      "metadata": {
        "id": "jyrtsZ7WhdLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "👋 ⚒ **Aufgaben** 👋 ⚒ <br>\n",
        "Berechnen Sie die Kosinus-Ähnlichkeit auf den ersten 10 Beispielen auf dem Datensatz und vergleichen Sie wie weit der Wert vom Goldstandard im Datensatz ist. Achtung: Der Goldstandard liegt im Wertebereich von 0 (vollkommen unterschiedlich) bis zu 5 (inhaltlich äquivalent).  "
      ],
      "metadata": {
        "id": "sinXnrzehtAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fügen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "JJNwgxGYjWaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}