{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNSHxqDSn8z+8H2zyUADubV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/Programmieren_fuer_Translator_innen_2024S/blob/main/notebooks/LV6_Sentence_Similarity_mit_L%C3%B6sungen.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2024S: Einf√ºhrung ins Programmieren f√ºr Translator:innen, √úbung (UE), 340273-1\n",
        "\n",
        "\n",
        "### **Speichern Sie dieses Notebook**\n",
        "\n",
        "Dieses Notebook k√∂nnen Sie jederzeit und in jedem Browser erneut von GitHub (bzw. dem direkten Link in Moodle) √∂ffnen. Um jedoch Ihre eigenen L√∂sungen und Ihren Code zu speichern, w√§hlen Sie bitte **Datei** bzw. **File** und eine der Speicheroptionen. Die einfachste Speicheroption ist in Google Drive, da dadurch √Ñnderungen im Notebook automatisch im Hintergrund gespeichert werden.\n",
        "\n",
        "F√ºr die Abgabe der praktischen √úbungen m√ºssen Sie jedoch das Jupyter-Notebook als .ipynb Datei herunterladen. Dazu klicken Sie auf **Datei** oder **File** und **Herunterladen** oder **Download** und w√§hlen das Format .ipynb aus."
      ],
      "metadata": {
        "id": "9gTU_wXn5DyC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation des Notebooks**\n",
        "\n",
        "Fragen und praktische Aufgaben werden hier als ‚ùì**Frage**‚ùì bzw. üëã ‚öí **Aufgabe** üëã ‚öí gekennzeichnet. ‚ùì**Fragen**‚ùì fordern Sie dazu auf √úberlegungen anzustellen bevor Sie etwas praktisch testen. üëã ‚öí **Aufgaben** üëã ‚öí erfordern das aktive Schreiben von Code in der grauen Code-Zelle nach der Beschreibung der Aufgabe."
      ],
      "metadata": {
        "id": "_Ha_gYIk5FGw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "## **Lektion 11: Sentence Similarity mit und ohne spaCy**\n",
        "Unter Sentence Similarity wird eine Metrik verstanden, welche die semantische N√§he von S√§tzen misst, im Gegensatz zu Metriken welche die √Ñhnlichkeit von W√∂rtern in Kontexten evaluiert.\n",
        "\n",
        "Eine Anwendung oder ein Modell der Sentence Similarity erh√§lt einen Satz als Eingabe und misst wie √§hnlich dieser Satz zu einem oder mehreren anderen S√§tzen ist. Dazu wird eine bestimmte Metrik verwendet, z. B. Levenshtein-Distanz oder Kosinus-√Ñhnlichkeit."
      ],
      "metadata": {
        "id": "ksxAGEVC5LbA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Levenshtein-Distanz**\n",
        "\n",
        "Die Levenshtein oder Edit-Distanz misst die Anzahl der folgenden Operationen um die eine Zeichenkette in die andere umzuwandeln: Einf√ºgen, L√∂schen, Ersetzen.\n",
        "\n",
        "Beispiel Tor-Tier:\n",
        "\n",
        "\n",
        "1.   Ausgangswert: Tor (Anzahl Operationen: 0)\n",
        "2.   Erstezen: \"o\" durch \"i\" zu Tir (Anzahl Operationen: 1)\n",
        "3.   Einf√ºgen: \"e\" zu Tier (Anzahl Operationen: 2)\n",
        "\n",
        "Diese Messung kann auf W√∂rter aber auch auf l√§ngere Zeichenketten wie S√§tze angewandt werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "GVCWYf38-ReV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Cosine-Similarity**\n",
        "Die Kosinus-√Ñhnlichkeit oder √ºblicher Cosine-Similarity bestimmt den Winkel zwischen zwei Vektoren. Dadurch ist es erforderlich erst die W√∂rter bzw. S√§tze in Vektoren umzuwandeln, um dann den Winkel zwischen den Vektoren messen zu k√∂nnen.\n",
        "\n",
        "![Cosine similarity](https://huggingface.co/datasets/huggingface-ml-4-games-course/course-images/resolve/main/en/unit1/unity/cosine.png)\n",
        "\n",
        "Dazu muss allerdings Text erst in Vektoren verwandelt werden. Danach kann anhand der folgenden Formel der Kosinus-Wert berechnet werden.\n",
        "\n",
        "![Kosinus](https://wikimedia.org/api/rest_v1/media/math/render/svg/5b18ea67495071781ab0d1379373872662fa6735)\n",
        "\n",
        "Die Kosinus-√Ñhnlichkeit liegt zwischen ‚àí1 (genau entgegengerichtet) und 1 (genau gleichgerichtet). Bei √Ñhnlichkeitsanalysen von Text liegt dieser Wert in der Regel im Bereich zwischen 0 und 1. Je n√§her der Wert zu 1 ist desto √§hnlicher sind die Zeichenketten.\n"
      ],
      "metadata": {
        "id": "MjgJpXAhAyaG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Anwendungsbeispiele**\n",
        "Diese Berechnung der √Ñhnlichkeiten zwischen Zeichenketten kann f√ºr viele verschiedene Anwendungen sehr hilfreich sein:\n",
        "\n",
        "\n",
        "*   Suchmaschinen\n",
        "*   Maschinelle √úbersetzung\n",
        "*   Informationsextraktion\n",
        "*   viele mehr\n",
        "\n"
      ],
      "metadata": {
        "id": "tBmisAm7LEFQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als erstes ben√∂tigen wir Beispiels√§tze. Wir verwenden zur Anschauung zwei S√§tze auf Deutsch und zwei S√§tze auf Englisch."
      ],
      "metadata": {
        "id": "Vf5-79jOFOz2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHsKFiuS4RAF"
      },
      "outputs": [],
      "source": [
        "sentence1_de = \"Ein Hund springt auf einem Trampolin.\"\n",
        "sentence2_de = \"Ein Hund h√ºpft auf einem Trampolin im Garten.\"\n",
        "\n",
        "sentence1_en = \"The quick brown fox jumps over the lazy dog.\"\n",
        "sentence2_en = \"The quick black dog jumps over the brown fox\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Im ersten Ansatz verwenden wir einen ganz simplen Ansatz, der einfach die H√§ufigkeiten von W√∂rtern des Gesamtvokabulars im Satz z√§hlt. Nehmen wir unsere beiden deutschen Beispiels√§tze:\n",
        "\n",
        "\n",
        "`Satz 1: Ein Hund springt auf einem Trampolin.`<br>\n",
        "`Satz 2: Ein Hund h√ºpft auf einem Trampolin im Garten.`\n",
        "\n",
        "\n",
        "F√ºr diesen Korpus besteht unser Gesamtvokabular aus allen W√∂rtern dieser beiden S√§tze ohne Wiederholungen:\n",
        "\n",
        "`{'einem', 'hund', 'garten', 'auf', 'im', 'h√ºpft', 'springt', 'ein', 'trampolin'}`"
      ],
      "metadata": {
        "id": "SYcq4Xm2F69N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Schreiben Sie eine Funktion, welche einen Satz √ºbergeben wird und die alle W√∂rter im Satz:\n",
        "\n",
        "\n",
        "1.   Kleinschreibung aller Buchstaben im Satz mit sentence.lower()\n",
        "2.   Tokenisierung aller W√∂rter in einem Satz und entfernen der Punkte (spaCy oder sentence.strip(\".\") + split())\n",
        "\n",
        "Die Funktion soll eine Liste mit allen kleingeschriebenen Tokens eines Satzes zur√ºckgeben. Falls Sie spaCy verwenden wollen, muss erst wieder alles geladen werden."
      ],
      "metadata": {
        "id": "ARihR-HDI3lm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "qdAN6qyKOB6U",
        "outputId": "e906211b-9002-4da3-b923-31fc0b39a082",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting de-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-3.7.0/de_core_news_sm-3.7.0-py3-none-any.whl (14.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from de-core-news-sm==3.7.0) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->de-core-news-sm==3.7.0) (1.1.1)\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('de_core_news_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m43.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n",
            "\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "ro2MODavOD1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante 1: ohne spaCy\n",
        "def preprocess(sentence):\n",
        "  # F√ºgen Sie hier Ihren Code hier ein\n",
        "  sentence_lower = sentence.lower()\n",
        "  sentence_lower_strip = sentence_lower.strip(\".\")\n",
        "  tokens = sentence_lower_strip.split()\n",
        "  return tokens\n",
        "\n",
        "sent1_tokens = preprocess(sentence1_de)\n",
        "print(sent1_tokens)"
      ],
      "metadata": {
        "id": "L0N5JsaMKvWR",
        "outputId": "cf7d94d3-0669-43b1-9445-baa4cc0799a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ein', 'hund', 'springt', 'auf', 'einem', 'trampolin']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Variante 2: mit spaCy\n",
        "def preprocess_spacy(sentence):\n",
        "  tokens = []\n",
        "  doc = nlp(sentence.lower())\n",
        "  for token in doc:\n",
        "    if token.pos_ != \"PUNCT\":\n",
        "      tokens.append(token)\n",
        "  return tokens\n",
        "\n",
        "preprocess_spacy(sentence1_de)"
      ],
      "metadata": {
        "id": "O0vJkSUlT65k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Die von Ihnen geschriebene Funktion verwenden wir nun um die Kosinus-√Ñhnlichkeit zu berechnen. In der nachstehenden Code-Zelle sehen Sie die Umsetzung der Kosinus-Formel in Python zur Berechnung der Text√§hnlichkeit.\n",
        "\n",
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Verwenden Sie den nachstehenden Code um die √Ñhnlichkeit der beiden englischen Beispiels√§tze zu berechnen. Beachten Sie, dass bei spaCy dann das geladene Modell ge√§ndert werden muss, wenn f√ºr die `preprocess`-Funktion spaCy verwendet wird."
      ],
      "metadata": {
        "id": "PbxAeoPuK0L1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "def vectorize(text, vocab):\n",
        "    # Erstellen einer Vektordarstellung auf Basis von Worth√§ufigkeiten\n",
        "    vector = [text.count(word) for word in vocab]\n",
        "    return vector\n",
        "\n",
        "def cosine_similarity(vec1, vec2):\n",
        "    # Kosinus-√Ñhnlichkeit zwischen den beiden Vektoren berechnen\n",
        "    dot_product = sum(x * y for x, y in zip(vec1, vec2))\n",
        "    magnitude_vec1 = math.sqrt(sum(x ** 2 for x in vec1))\n",
        "    magnitude_vec2 = math.sqrt(sum(y ** 2 for y in vec2))\n",
        "    if magnitude_vec1 == 0 or magnitude_vec2 == 0:\n",
        "        return 0\n",
        "    else:\n",
        "        return dot_product / (magnitude_vec1 * magnitude_vec2)\n",
        "\n",
        "sentence1_tokens = preprocess(sentence1_de)\n",
        "sentence2_tokens = preprocess(sentence2_de)\n",
        "\n",
        "# Gesamtvokabular erstellen\n",
        "vocabulary = set(sentence1_tokens + sentence2_tokens)\n",
        "\n",
        "# Vektoren f√ºr die beiden S√§tze berechnen\n",
        "sentence1_vector = vectorize(sentence1_tokens, vocabulary)\n",
        "sentence2_vector = vectorize(sentence2_tokens, vocabulary)\n",
        "print(\"Vokabular:\", vocabulary)\n",
        "print(\"Vektor Satz 1:\", sentence1_vector)\n",
        "print(\"Vektor Satz 2:\", sentence2_vector)\n",
        "\n",
        "# Kosinus-√Ñhnlichkeit zwischen diesen beiden Vektoren berechnen\n",
        "cos_similarity = cosine_similarity(sentence1_vector, sentence2_vector)\n",
        "\n",
        "print(\"Satz 1:\", sentence1_de)\n",
        "print(\"Satz 2:\", sentence2_de)\n",
        "print(\"√Ñhnlichkeit:\", cos_similarity)"
      ],
      "metadata": {
        "id": "6YD0kcbKGdyz",
        "outputId": "09872b77-b3fc-490f-8137-6c57ecd0f851",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'auf', 'springt', 'trampolin', 'h√ºpft', 'ein', 'im', 'hund', 'garten', 'einem'}\n",
            "[1, 1, 1, 0, 1, 0, 1, 0, 1]\n",
            "[1, 0, 1, 1, 1, 1, 1, 1, 1]\n",
            "Satz 1: Ein Hund springt auf einem Trampolin.\n",
            "Satz 2: Ein Hund h√ºpft auf einem Trampolin im Garten.\n",
            "√Ñhnlichkeit: 0.7216878364870323\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In spaCy gibt die M√∂glichkeit W√∂rter und S√§tze direkt in Vektoren darzustellen, da die spaCy-Modelle bereits Vektordarstellungen bereitstellen. Diese Vektoren z√§hlen aber nicht die im Satz enthaltenen W√∂rter, sondern verwenden neuronale Netze um W√∂rter in Vektoren darzustellen.\n",
        "\n",
        "Falls Sie die Code-Zellen oben nicht ausgef√ºhrt haben, dann f√ºhren Sie bitte die folgenden Code-Zellen aus um die spaCy-Modelle und Programmbibliothek zu laden. Die verschiedenen vortrainierten Modelle in spaCy finden sie [hier](https://spacy.io/models/en).\n",
        "\n"
      ],
      "metadata": {
        "id": "KchEAcYuNKRi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "L589-bFgORK9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "TI145lWMOa5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann kann spaCy direkt verwendet werden um Vektoren zu erstellen."
      ],
      "metadata": {
        "id": "H8_e3wVDOf0V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(\"Tor\").vector"
      ],
      "metadata": {
        "id": "d1ZvQbT9OfOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dasselbe funktionert auch f√ºr S√§tze."
      ],
      "metadata": {
        "id": "WxlNBScwOo3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp(sentence1_de).vector"
      ],
      "metadata": {
        "id": "GrVEiuniOqfA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um nun S√§tze zu vergleichen, k√∂nnen in spaCy enthaltene Funktionen verwendet werden."
      ],
      "metadata": {
        "id": "3QQteiSoPCP_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc1 = nlp(sentence1_de)\n",
        "doc2 = nlp(sentence2_de)\n",
        "\n",
        "similarity = doc1.similarity(doc2)\n",
        "print(similarity)"
      ],
      "metadata": {
        "id": "xWCDlyKbPGsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Oder wir verwenden die Vektordarstellungen in unserer `cosine_similarity`-Funktion. Das Ergebnis ist dasselbe."
      ],
      "metadata": {
        "id": "h968FxRtPXxt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similarity =cosine_similarity(nlp(sentence1_de).vector, nlp(sentence2_de).vector)\n",
        "print(similarity)"
      ],
      "metadata": {
        "id": "-W8ZJRm4PXFl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Berechnen Sie die Kosinus-√Ñhnlichkeit auf den beiden englischen Beispiels√§tzen mithilfe von spaCy. Achtung: Dazu muss das richtige Modelle in spaCy geladen werden."
      ],
      "metadata": {
        "id": "Lw44GsdbPpuL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "eKhUPqk4QjU3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Lektion 12: Sentence Similarity mit Hugging Face ü§ó**\n",
        "\n",
        "[Hugging Face](https://huggingface.co/) ü§ó ist eine Platform f√ºr maschinelles Lernen, Computerlinguistik und Data Science. NLP-Expert*innen und -Begeisterte teilen auf Hugging Face vortrainierte Modelle, Datens√§tze, Code und Informationen.\n",
        "\n",
        "Die Platform selbst bietet einheitliche Methoden um Modelle und Datens√§tze in Python zu laden und zu verwenden. Um Hugging Face in Google Colab nutzen zu k√∂nnen m√ºssen wir zwei Bibliotheken von Hugging Face installieren."
      ],
      "metadata": {
        "id": "QxZ0uvu7Q1HP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers\n",
        "!pip install datasets"
      ],
      "metadata": {
        "id": "7YjHCJkhXNBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Der gro√üe Unterschied zu den vorherigen Methoden ist, dass wir mithilfe von Hugging Face die Vektordarstellung von gro√üen vortrainierten Modellen abrufen k√∂nnen."
      ],
      "metadata": {
        "id": "l8-IqDFwXOwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\n",
        "\n",
        "model = SentenceTransformer('sentence-transformers/stsb-xlm-r-multilingual')\n",
        "\n",
        "# Vektordarstellung der beiden S√§tze abrufen\n",
        "embedding_1= model.encode(sentence1_de)\n",
        "embedding_2 = model.encode(sentence2_de)\n",
        "\n",
        "cos_sim = util.pytorch_cos_sim(embedding_1, embedding_2)\n",
        "print(\"Die Kosinus-√Ñhnlichkeit ist:\", cos_sim.item())"
      ],
      "metadata": {
        "id": "E6MTPvKvWyeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mithilfe von Hugging Face k√∂nnen wir auch bereits existierende Datens√§tze laden und verwenden, z. B.[Glue](https://huggingface.co/datasets/nyu-mll/glue) mit vielen verschiedenen Tasks einschlie√ülich Semantic Textual Similarity."
      ],
      "metadata": {
        "id": "PH4_VO0lbMhp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"nyu-mll/glue\", \"stsb\")\n",
        "\n",
        "print(dataset)"
      ],
      "metadata": {
        "id": "inrZ7K09bb2s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann k√∂nnen die einzelnen drei Teile des Datensatzes `train`, `validation`, `test` direkt angesprochen werden und wie ein Key eines Dictionarys behandelt werden.\n",
        "\n"
      ],
      "metadata": {
        "id": "sFzN4raPdDF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(dataset['train'][10])"
      ],
      "metadata": {
        "id": "nXzIL3EIdDef"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Und √ºber diesen Datentypen kann auch iteriert werden. Die Funktion `select(range(10))`dient hier der Auswahl von 10 Beispielen.  "
      ],
      "metadata": {
        "id": "hDj8BHtXha6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for line in dataset['train'].select(range(10)):\n",
        "  print(line)"
      ],
      "metadata": {
        "id": "jyrtsZ7WhdLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Berechnen Sie die Kosinus-√Ñhnlichkeit auf den ersten 10 Beispielen auf dem Datensatz und vergleichen Sie wie weit der Wert vom Goldstandard im Datensatz ist. Achtung: Der Goldstandard liegt im Wertebereich von 0 (vollkommen unterschiedlich) bis zu 5 (inhaltlich √§quivalent).  "
      ],
      "metadata": {
        "id": "sinXnrzehtAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "JJNwgxGYjWaM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}