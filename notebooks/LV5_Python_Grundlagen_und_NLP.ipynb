{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPy9H+3qytvVAXgNBrZxp8d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dgromann/Programmieren_fuer_Translator_innen_2024S/blob/main/notebooks/LV5_Python_Grundlagen_und_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2024S: Einf√ºhrung ins Programmieren f√ºr Translator:innen, √úbung (UE), 340273-1**\n",
        "\n",
        "### **Speichern Sie dieses Notebook**\n",
        "\n",
        "Dieses Notebook k√∂nnen Sie jederzeit und in jedem Browser erneut von GitHub (bzw. dem direkten Link in Moodle) √∂ffnen. Um jedoch Ihre eigenen L√∂sungen und Ihren Code zu speichern, w√§hlen Sie bitte **Datei** bzw. **File** und eine der Speicheroptionen. Die einfachste Speicheroption ist in Google Drive, da dadurch √Ñnderungen im Notebook automatisch im Hintergrund gespeichert werden.\n",
        "\n",
        "F√ºr die Abgabe der praktischen √úbungen m√ºssen Sie jedoch das Jupyter-Notebook als .ipynb Datei herunterladen. Dazu klicken Sie auf **Datei** oder **File** und **Herunterladen** oder **Download** und w√§hlen das Format .ipynb aus."
      ],
      "metadata": {
        "id": "gObUy6kxDYch"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Notation des Notebooks**\n",
        "\n",
        "Fragen und praktische Aufgaben werden hier als ‚ùì**Frage**‚ùì bzw. üëã ‚öí **Aufgabe** üëã ‚öí gekennzeichnet. ‚ùì**Fragen**‚ùì fordern Sie dazu auf √úberlegungen anzustellen bevor Sie etwas praktisch testen. üëã ‚öí **Aufgaben** üëã ‚öí erfordern das aktive Schreiben von Code in der grauen Code-Zelle nach der Beschreibung der Aufgabe.\n"
      ],
      "metadata": {
        "id": "bqYjNoLIDgYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "## **Lektion 9: Python √ºben**\n",
        "\n",
        "In dieser Lektion liegt der Fokus auf der Wiederholung vorheriger Inhalte und dem Datentyp Dictionary."
      ],
      "metadata": {
        "id": "AR4JsE40DoA8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ijp0zS-QDTmP"
      },
      "outputs": [],
      "source": [
        "# Beispiel Dictionary\n",
        "lit_dict = {\n",
        "    \"Die Blechtrommel\": \"G√ºnter Grass\",\n",
        "    \"Qualityland\": \"Marc-Uwe Kling\",\n",
        "    \"Die Verwandlung\": \"Franz Kafka\",\n",
        "    \"Die Klavierspielerin\": \"Elfriede Jelinek\",\n",
        "    \"Die Schachnovelle\": \"Stefan Zweig\"\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Bitte f√ºgen Sie dem Dictionary `lit_dict` ein weieres Werk Ihrer Wahl samt dessen Autor*in mithilfe von Python-Code hinzu."
      ],
      "metadata": {
        "id": "dcbW0mhSL3tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "mFEP0cJuMd6B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Schreiben Sie eine Funktion die z√§hlt und ausgibt, wie viele Keys und Values das Dictionary 'lit_dict'."
      ],
      "metadata": {
        "id": "Cypg5IceMigA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "c8-PS16feGVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Nun schauen wir uns an, wie eine Datei in Python geladen und gespeichert werden kann. Gehen Sie dazu zu dem [GitHub-Repository dieses Kurses](https://github.com/dgromann/Programmieren_fuer_Translator_innen_2024S), klicken Sie auf die datei `Text1.txt` und w√§hlen Sie dann im Men√º der drei Punkte oben rechts die Option Download aus.\n",
        "\n",
        "Speichern Sie die Datei lokal in einem Ordner Ihrer Wahl und laden Sie dann die Datei in diesem Notebook hoch. Dazu klicken Sie bitte auf den Ordner in der rechten Leiste und ziehen Sie die Datei `Text1.txt`  in diesen Ordner."
      ],
      "metadata": {
        "id": "QE5jmGdqeHWa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file1 = open(\"Text1.txt\")\n",
        "\n",
        "text1 = file1.read()\n",
        "\n",
        "print(text1)"
      ],
      "metadata": {
        "id": "wfqBEtZKjGfM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "chCKP4aqkHi2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Schreiben Sie nun eine Funktion, welche die H√§ufigkeiten der W√∂rter mithilfe eines Dictionary z√§hlt und zur√ºckgibt. Verwenden Sie als Beispieltext den Text aus der Datei `Text1.txt`."
      ],
      "metadata": {
        "id": "5GckD5ysjluc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "2XskKc1ljwQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "-----------\n",
        "## **Lektion 10: Natural Language Processing mit spaCy**\n",
        "\n",
        "In dieser √úbung √ºben wir die erste Verwendung der Programmierbibliothek [spaCy](https://spacy.io/), eine sehr umfangreiche und hilfreiche Bibliothek f√ºr Natural Language Processing.\n",
        "\n",
        "Als erste m√ºssen wir die Bibliothek und die erforderlichen Modelle installieren."
      ],
      "metadata": {
        "id": "Wodx6-tij1oI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download de_core_news_sm\n",
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "id": "LOXqXGHXki8Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dann muss die Bibliothek importiert werden, damit wir die darin enthaltenen Funktionen nutzen k√∂nnen."
      ],
      "metadata": {
        "id": "UGSqGr36nGR-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy"
      ],
      "metadata": {
        "id": "6XqBFMFLnEqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Als n√§chsten Schritt laden wir uns das Modell von spaCy in der richtigen Sprache, welche f√ºr diese √úbung Deutsch ist. Daher laden wir das Modell `de_core_news_sm`. Wenn wir Englisch verwenden, m√º√üten wir z. B. `en_core_web_sm` stattdessen laden."
      ],
      "metadata": {
        "id": "qxUlODXrloaX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"de_core_news_sm\")"
      ],
      "metadata": {
        "id": "kpJw6VdnktKB"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Tokenisierung und POS Tagging\n",
        "Um spaCy zu verwenden, kann der Text einfach dem Obhekt NLP √ºbergeben werden.\n",
        "\n",
        "POS Tagging ist das automatische erkennen der Wortklasse (Part-of-Speech oder kurz POS) eines Wortes und Angabe dieser Wortklasse als Annotation.\n"
      ],
      "metadata": {
        "id": "5KifQUiKnYZS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = nlp(\"Apple ist ein riesiger Softwarekonzern mit Hauptsitz in den USA . Eines der wichtigsten Produkte der Firma ist der Computer Mac kurz f√ºr Macintosh der nach der Lieblingsapfelsorte des Entwirkclers benannt ist.\")\n",
        "\n",
        "doc = nlp(text)\n",
        "\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_)"
      ],
      "metadata": {
        "id": "DdE4a3ppnqxm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Um eine Erkl√§rung der einzelnen POS-Tags mitauszugeben, k√∂nnen wir einfach `spacy.explain(token.pos_)`hinzuf√ºgen:"
      ],
      "metadata": {
        "id": "07NE2748pbBA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.tag_, spacy.explain(token.pos_))"
      ],
      "metadata": {
        "id": "DTkjSIrMpirk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatisierung\n",
        "\n",
        "Ebenso leicht k√∂nnen W√∂rter mithilfe von spaCy auf Stammformen umgewandelt werden.  "
      ],
      "metadata": {
        "id": "GgIylbDUp8Pp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.lemma_)"
      ],
      "metadata": {
        "id": "5pRMbVoQqN0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "W√§hlen Sie einen eigenen Beispielsatz Ihrer Wahl und f√ºhren Sie darauf Tokenisierung, POS-Tagging und Lemmatisierung durch. Werden die Wortklassen immer richtig erkannt?"
      ],
      "metadata": {
        "id": "wwyo6H5vqV79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "EkmRhlLuqkkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Named Entity Recognition\n",
        "Mithilfe von spaCy k√∂nnen wir auch Eigenname in Texten automatisch erkennen.\n"
      ],
      "metadata": {
        "id": "yShSOGRwqoKA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for ent in doc.ents:\n",
        "    print(ent.text, ent.start_char, ent.end_char, ent.label_)"
      ],
      "metadata": {
        "id": "4R5mRzgzq7a2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In spaCy gibt es auch eine Funktion, um die Eigenenamen in Text samt dem Label direkt im Text farblich markieren zu lassen."
      ],
      "metadata": {
        "id": "KIU9Ri0Irgz0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"ent\")"
      ],
      "metadata": {
        "id": "5ILJr8QlrIU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "üëã ‚öí **Aufgaben** üëã ‚öí <br>\n",
        "Schreiben Sie nun eine Funktion, welche den Text enthalten in der Datei `Text1.txt`√ºbernimmt und die H√§ufigkeiten der W√∂rter nach der Tokenisierung und Lemmatisierung mit spaCy z√§hlt. Hat sich der Wert zur vorherigen Funktion ver√§ndert?"
      ],
      "metadata": {
        "id": "6bqT5VODprHC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# F√ºgen Sie hier Ihren Code hier ein"
      ],
      "metadata": {
        "id": "Ze-t3V0WpjxT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dependency Parsing\n",
        "Zuletzt analysieren wir noch die F√§higkeit von spaCy grammatikalische Beziehungen automatisch zu erkennen, also Dependency Parsing.\n"
      ],
      "metadata": {
        "id": "ofdomreKsOYa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "            [child for child in token.children])"
      ],
      "metadata": {
        "id": "JuNiBd4Xsf-h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Diese Beziehungen k√∂nnen auch graphisch angezeigt werden."
      ],
      "metadata": {
        "id": "sxWrNfbqsm8S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from spacy import displacy\n",
        "displacy.render(doc, style=\"dep\", jupyter=True)"
      ],
      "metadata": {
        "id": "UDLxA6cusqxU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}